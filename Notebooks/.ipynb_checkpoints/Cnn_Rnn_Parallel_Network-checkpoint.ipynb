{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import os\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.python.keras import utils\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "with open(\"../Genre_Track_Id_Dict.json\",'r') as j:\n",
    "    id_genre_dict = json.load(j)\n",
    "numerical_labels = dict(zip(list(id_genre_dict.keys()),np.arange(0,8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((56000,128,647))\n",
    "labels = np.zeros((56000,len(numerical_labels)))\n",
    "\n",
    "ct=-1\n",
    "for genre in os.listdir(\"../mp3_files\"):\n",
    "    genre_dir = os.path.join(\"../mp3_files\",genre)\n",
    "    for fname in [f for f in os.listdir(genre_dir) if \".tiff\" in f]:\n",
    "        mel_db_path = os.path.join(genre_dir,fname)\n",
    "        try:\n",
    "\n",
    "            spect = tifffile.imread(mel_db_path)\n",
    "            if spect.shape[1] == 646:\n",
    "                spect = np.hstack((spect,np.zeros((128,1))))\n",
    "            if spect.shape[1] == 647:\n",
    "                ct+=1\n",
    "                data[ct,:,:] = spect\n",
    "                genre_encode = numerical_labels[genre] \n",
    "                labels[ct][genre_encode] = 1\n",
    "        except:\n",
    "            idk = 2\n",
    "data = data[0:ct,:,:]\n",
    "labels = labels[0:ct,:]\n",
    "\n",
    "data = data/-80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (39169, 128, 647, 1) ... (39169, 8)\n",
      "Testing Shape: (13430, 128, 647, 1) ... (13430, 8)\n",
      "Validation Shape: (3358, 128, 647, 1) ... (3358, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.30, shuffle=True)\n",
    "X_train = X_train.reshape(X_train.shape[0], 128, 647, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 128, 647, 1)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.20, shuffle=True)\n",
    "\n",
    "print(\"Training Shape: {} ... {}\".format(X_train.shape,y_train.shape))\n",
    "print(\"Testing Shape: {} ... {}\".format(X_test.shape,y_test.shape))\n",
    "print(\"Validation Shape: {} ... {}\".format(X_val.shape,y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paddings = tf.constant([[0, 0],[1,1],[1,1],[0,0]])\n",
    "visible = Input(shape=(128,647,1))\n",
    "\n",
    "#CNN Block\n",
    "padded_input = tf.pad(visible,paddings,\"CONSTANT\")\n",
    "\n",
    "cnn_conv_1 = BatchNormalization(axis=-1)(Conv2D(16,(3,3),activation='relu',input_shape=(130,649,1))(padded_input))\n",
    "cnn_mp_1 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(cnn_conv_1)\n",
    "\n",
    "cnn_padded_2 = tf.pad(cnn_mp_1,paddings,\"CONSTANT\")\n",
    "cnn_conv_2 = BatchNormalization(axis=-1)(Conv2D(32,(3,3),activation='relu')(cnn_padded_2))\n",
    "cnn_mp_2 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(cnn_conv_2)\n",
    "\n",
    "cnn_padded_3 = tf.pad(cnn_mp_2,paddings,\"CONSTANT\")\n",
    "cnn_conv_3 = BatchNormalization(axis=-1)(Conv2D(64,(3,3),activation='relu')(cnn_padded_3))\n",
    "cnn_mp_3 = layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(cnn_conv_3)\n",
    "\n",
    "cnn_padded_4 = tf.pad(cnn_mp_3,paddings,\"CONSTANT\")\n",
    "cnn_conv_4 = BatchNormalization(axis=-1)(Conv2D(128,(3,3),activation='relu')(cnn_padded_4))\n",
    "cnn_mp_4 = layers.MaxPooling2D(pool_size=(4,4),strides=(4,4))(cnn_conv_4)\n",
    "\n",
    "cnn_padded_5 = tf.pad(cnn_mp_4,paddings,\"CONSTANT\")\n",
    "cnn_conv_5 = BatchNormalization(axis=-1)(Conv2D(64,(3,3),activation='relu')(cnn_padded_5))\n",
    "cnn_mp_5 = layers.MaxPooling2D(pool_size=(4,4),strides=(4,4))(cnn_conv_5)\n",
    "\n",
    "cnn_out = layers.Flatten()(cnn_mp_5)\n",
    "\n",
    "# #Rnn Block \n",
    "rnn_mp = layers.MaxPooling2D(pool_size=(1,2),strides=(1,2))(visible)\n",
    "lstm_unit = layers.LSTM(1,return_sequences=False,return_state=False)\n",
    "rnn_lstm = layers.Bidirectional(lstm_unit)(tf.reshape(rnn_mp,rnn_mp.shape[1:]))\n",
    "rnn_out = layers.Flatten()(rnn_x)\n",
    "\n",
    "# # rnn_x = layers.Embedding(input_dim = 27520, output_dim = 16384)(rnn_x)\n",
    "# #missing embedding\n",
    "# rnn_x = tf.reshape(rnn_x,rnn_x.shape[1:])\n",
    "# rnn_x = layers.Bidirectional(gru)(rnn_x)\n",
    "# rnn_out = tf.reshape(rnn_x,(256,))#layers.Flatten()(rnn_x)\n",
    "\n",
    "# # combined_tensor = tf.concat([rnn_out,cnn_out],axis=0)\n",
    "# # combined_tensor = tf.reshape(combined_tensor,(512,1))\n",
    "\n",
    "out = layers.Dense(8, activation=\"softmax\")(cnn_out)\n",
    "\n",
    "model = Model(inputs=visible, outputs=out)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##### Think about this ConvLSTM2D\n",
    "\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# visible = Input(shape=(128,647,1))\n",
    "# rnn_mp = layers.MaxPooling2D(pool_size=(1,2),strides=(1,2))(visible)\n",
    "# lstm_unit = layers.LSTM(128, return_sequences=False,return_state=False)\n",
    "# rnn_mp_reshape = tf.reshape(rnn_mp,BATCH_SIZE+rnn_mp.shape[1:-1])\n",
    "# rnn_lstm = lstm_unit(rnn_mp_reshape)\n",
    "\n",
    "\n",
    "# out = layers.Dense(8, activation=\"softmax\")(rnn_lstm)\n",
    "# model = Model(inputs=visible, outputs=out)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1225/1225 [==============================] - 4983s 4s/step - loss: 1.7164 - accuracy: 0.3957 - val_loss: 1.9124 - val_accuracy: 0.3669\n",
      "INFO:tensorflow:Assets written to: Network_Results/Rnn_Cnn_Parallel_Checkpoint/assets\n",
      "Epoch 2/30\n",
      "1225/1225 [==============================] - 4949s 4s/step - loss: 1.2332 - accuracy: 0.5698 - val_loss: 1.6917 - val_accuracy: 0.4876\n",
      "INFO:tensorflow:Assets written to: Network_Results/Rnn_Cnn_Parallel_Checkpoint/assets\n",
      "Epoch 3/30\n",
      "1225/1225 [==============================] - 4957s 4s/step - loss: 1.0603 - accuracy: 0.6288 - val_loss: 1.8445 - val_accuracy: 0.4273\n",
      "INFO:tensorflow:Assets written to: Network_Results/Rnn_Cnn_Parallel_Checkpoint/assets\n",
      "Epoch 4/30\n",
      "1225/1225 [==============================] - 4962s 4s/step - loss: 0.8917 - accuracy: 0.6881 - val_loss: 2.0720 - val_accuracy: 0.4297\n",
      "INFO:tensorflow:Assets written to: Network_Results/Rnn_Cnn_Parallel_Checkpoint/assets\n",
      "Epoch 5/30\n",
      "1225/1225 [==============================] - 4970s 4s/step - loss: 0.7200 - accuracy: 0.7456 - val_loss: 2.4477 - val_accuracy: 0.4153\n",
      "INFO:tensorflow:Assets written to: Network_Results/Rnn_Cnn_Parallel_Checkpoint/assets\n",
      "Epoch 6/30\n",
      "1159/1225 [===========================>..] - ETA: 4:02 - loss: 0.4977 - accuracy: 0.8277"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = \"Network_Results/Rnn_Cnn_Parallel_Checkpoint\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    save_best_only=False)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                        y_train, \n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        epochs=30,\n",
    "                        callbacks = model_checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
