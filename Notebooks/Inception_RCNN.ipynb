{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import (Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, \n",
    "Permute, Reshape, GRU)\n",
    "from tensorflow.python.keras import utils\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "import tifffile \n",
    "\n",
    "with open(\"../Genre_Track_Id_Dict.json\",'r') as j:\n",
    "        id_genre_dict = json.load(j)\n",
    "numerical_labels = dict(zip(list(id_genre_dict.keys()),np.arange(0,8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The idea of this notebook is to fuse the methods presented in:\n",
    "https://arxiv.org/pdf/1901.04555.pdf AND \n",
    "Bottom up broadcast neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"Spectrogram_Data.npy\")\n",
    "labels = np.load(\"Spectrogram_Data_Labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.30, shuffle=True)\n",
    "X_train = X_train.reshape(X_train.shape[0], 128, 647, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 128, 647, 1)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.20, shuffle=True)\n",
    "\n",
    "print(\"Training Shape: {} ... {}\".format(X_train.shape,y_train.shape))\n",
    "print(\"Testing Shape: {} ... {}\".format(X_test.shape,y_test.shape))\n",
    "print(\"Validation Shape: {} ... {}\".format(X_val.shape,y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(128,647,1))\n",
    "\n",
    "rcnn_res = crnn_module(visible)\n",
    "broadcast_res = broadcast_module(visible)\n",
    "\n",
    "both_modules = concatenate([rcnn_res,broadcast_res])\n",
    "\n",
    "out = layers.Dense(8, activation=\"softmax\")(both_modules)\n",
    "\n",
    "model = Model(inputs=visible, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crnn_module(input_tensor):\n",
    "    \"\"\"\n",
    "    will return rcnn module as seen in:\n",
    "    https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/music_tagger_crnn.py\n",
    "    \"\"\"\n",
    "    nb_layers = 4  # number of convolutional layers\n",
    "    nb_filters = [64, 128, 128, 128]  # filter sizes\n",
    "    kernel_size = (3, 3)  # convolution kernel size\n",
    "    activation = 'elu'  # activation function to use after each layer\n",
    "    pool_size = [(2, 2), (4, 2), (4, 2), (4, 2),\n",
    "                 (4, 2)]  # size of pooling area\n",
    "\n",
    "\n",
    "    input_shape = input_tensor.shape\n",
    "    frequency_axis = 1\n",
    "    time_axis = 2\n",
    "    channel_axis = 3\n",
    "\n",
    "\n",
    "    bn_1 = BatchNormalization(axis=frequency_axis, input_shape=input_shape)(input_tensor)\n",
    "    conv_1 = Conv2D(nb_filters[0], kernel_size=kernel_size, padding='same',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape,activation='elu')(bn_1)\n",
    "\n",
    "    bn_2 = BatchNormalization(axis=channel_axis)(conv_1)\n",
    "    mp_1 = MaxPooling2D(pool_size=pool_size[0], strides=pool_size[0])(bn_2)\n",
    "    drop_n = Dropout(0.1)(mp_1)\n",
    "\n",
    "    for layer in range(nb_layers - 1):\n",
    "        conv_n = Conv2D(nb_filters[layer + 1], kernel_size=kernel_size,\n",
    "                         padding='same', activation = 'elu')(drop_n)\n",
    "        bn_n = BatchNormalization(axis=channel_axis)(conv_n)\n",
    "        mp_n = MaxPooling2D(pool_size=pool_size[layer + 1],\n",
    "                               strides=pool_size[layer + 1])(bn_n)\n",
    "        drop_n = Dropout(0.1)(mp_n)\n",
    "\n",
    "    perm = Permute((time_axis, frequency_axis, channel_axis))(drop_n)\n",
    "    resize_shape = drop_n.shape[1] * drop_n.shape[3]\n",
    "    reshaped = Reshape((drop_n.shape[2], resize_shape))(perm)\n",
    "\n",
    "    gru_1 = GRU(32, return_sequences=True)(reshaped)\n",
    "    gru_2 = GRU(32, return_sequences=False)(gru_1)\n",
    "    output = Dropout(0.3)(gru_2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def broadcast_module(input_tensor):\n",
    "    \"\"\"\n",
    "    Will run input tensor through broadcast module as described in:\n",
    "    \n",
    "    \"\"\"\n",
    "    paddings = tf.constant([[0, 0],[1,1],[1,1],[0,0]])\n",
    "    padded_input = tf.pad(input_tensor,paddings,\"CONSTANT\")\n",
    "    x = Conv2D(32,(3,3),activation='relu',input_shape=(128,647,1))(padded_input)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    incept_1_input = MaxPooling2D(pool_size=(1,4),name='incept_1_input')(x)\n",
    "\n",
    "    f1 = 32\n",
    "    f2_in = 64\n",
    "    f2_out = 32\n",
    "    f3_in = 16\n",
    "    f3_out = 32\n",
    "    f4_out = 32\n",
    "\n",
    "    #Inception Module\n",
    "    incept_1 = inception_module(incept_1_input, f1, f2_in, f2_out, f3_in, f3_out, f4_out,1)\n",
    "\n",
    "    incept_2_input = concatenate([incept_1,incept_1_input],name='incept_2_input')\n",
    "    incept_2 = inception_module(incept_2_input, f1, f2_in, f2_out, f3_in, f3_out, f4_out,2)\n",
    "\n",
    "    incept_3_input = concatenate([incept_2_input,incept_2],name='incept_3_input')\n",
    "    incept_3 = inception_module(incept_3_input, f1, f2_in, f2_out, f3_in, f3_out, f4_out,3)\n",
    "\n",
    "    incept_3_output = concatenate([incept_3,incept_3_input],name='incept_3_output')\n",
    "\n",
    "    #Transition Layers\n",
    "    x = BatchNormalization(axis=-1)(Conv2D(32,(1,1))(incept_3_output))\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2),strides=2)(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# function for creating a projected inception module\n",
    "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out, n):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu',name=f'1x1_conv__{n}')(BatchNormalization(axis=-1)(layer_in))\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu',)(BatchNormalization(axis=-1)(layer_in))\n",
    "    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu',name=f'3x3_conv__{n}')(BatchNormalization(axis=-1)(conv3))\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(BatchNormalization(axis=-1)(layer_in))\n",
    "    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu',name=f'5x5_conv__{n}')(BatchNormalization(axis=-1)(conv5))\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(BatchNormalization(axis=-1)(pool))\n",
    "    # concatenate filters, assumes filters/channels last\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
